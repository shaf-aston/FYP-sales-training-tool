######################################################################
# SOURCE: Analyses.docx
# SIZE: 69.2 KB
######################################################################

Hardware Constraints

Available Resources:

RAM: 3GB usable (5 GB reserved for system , 11GB shown, but Windows/VSCode using 8GB)

CPU: 2.7GHz 8-core (decent for inference, slow for training)

GPU: 4GB dedicated + 6GB shared = 10GB total VRAM

Bottleneck: RAM (3GB) is critical constraint

Choosing STT model

Choose: Google STT

Instant results (<1 sec for short audio)

No local processing burden

Your ThinkPad stays responsive

Trade-off: ~17-20% WER vs Whisper's 8-10%

Faster-Whisper on Intel i7-12700K (8 threads):

For 13 minutes of audio:

Large-v3-turbo: ~4-5 minutes (0.3-0.4x real-time)

Large-v2: ~7-8 minutes (0.5-0.6x real-time)

Medium: ~3-4 minutes (0.25-0.3x real-time)

Small: ~2 minutes (0.15x real-time)

Whisper Small: ~12-15% WER

Choosing LLM model

I switched from Qwen2.5-0.5B → Qwen2.5-1.5B (3x better quality) because former model experienced problems like …..

Also explore comparing with Qwen2.5-1.5B-Instruct and >> Phi-2 (2.7B) - Excellent reasoning (8.5/10), needs 5GB VRAM

If better Hardware available (16GB RAM, 24GB VRAM)

Ideal Model: Mistral-7B-Instruct or Llama-3.1-8B

Sales Chatbot Benefits:

Better NEPQ Execution: Understands subtle questioning techniques (Needs and Pain points, natural scepticism),

Natural/ Humanised: Call length can cause fatigue, realisation of time, urgency and emotions created, experiences human biases and fallacies, and other human behaviour etc

Context Retention: Remembers earlier conversation points for better follow-up 

Personality Consistency: Minimises cognitive dissonance, but price may change their personality a lot

Better Improvisation: Handles unexpected sales directions naturally

Quality Difference:

My 1.5B model: Sometimes robotic, loses context after 5-6 turns

7-8B model: Near-human, maintains context 20+ turns, understands nuance

Challenges that I overcame:

Giving random syntax e.g #### or *****, or “Salesperson: “

Switching to the wrong role: Giving salesperson answers

Long response time solved by output token limits then it was truncating sentences tho

Url Links and endpoints had to be created for different pages for navigation rather than having everything on just one url – could explain reason for having multiple urls advantage over just one url decision-making process

Research and Analysis of Inspiration

S

todo list – Trello (Kanban)

Integrate SPM principles and where am I using (including estimates)

Research on tech to use

document previus trial and erroring code and ai

Journey of Development

Learning for development – Running ai generated code and analysing outputs for ideas. First I started with a project intended for QWEN 1.5 usage but it was giving truncated responses and uncontrolled conversations that were very irrelevant to the context of the conversation. Also, giving it databases of data without seeing how it was interpreting it was an issue, as it was interpreting it the way it thought was most relevant. 

Asking ai to run tests and Dry Runs for accurate code reviewing

Meeting:

I rely a lot on existing data for training so ethics form 

What I need to do is, state below 

Best saying if it is encrypted server and password protected and restricted access etc, limited people can access i.e me and my supervisor