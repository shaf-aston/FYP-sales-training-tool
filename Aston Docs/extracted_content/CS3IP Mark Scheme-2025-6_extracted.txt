================================================================================
[DOCUMENT METADATA]
================================================================================
FILE: CS3IP Mark Scheme-2025-6.pdf
EXTRACTION DATE: 2026-01-20 21:49:23
TYPE: PDF
================================================================================

################################################################################
[SECTION 1: TEXT CONTENT]
################################################################################

================================================================================
Page 1
================================================================================
CS3IP: Individual Project Mark Scheme 
Introduction 
Given the diversity of projects carried out for this module, the mark scheme has of 
necessity to be quite general in nature, and based around the learning objectives set for 
the module: - 
LO1: Ability to specify and carry out a Computer Science project of significant scope and 
size independently. 
LO2: Ability to integrate knowledge from a variety of sources 
LO3: Ability to produce a high-quality technical report describing and evaluating the 
outcomes of a technical endeavour 
LO4: Ability in coherent demonstration and verbal exposition of own work 
A primary consideration (bound up with our British Computer Society accreditation) is 
that the work should demonstrate at least part of the software development lifecycle in 
action. For the purposes of this module, the stages in the lifecycle are Requirements, 
Design, Implementation, Verification and Maintenance. Whilst it is easy to apply these 
stages to a project that produces a ‘deliverable’ in the shape of a piece of software, 
research-based projects should address at least one stage, and identify it clearly. 
It is recommended that those conducting research encapsulate a conventional research 
paper with a narrative that indicates how they managed their research project to meet 
LO1. 
To this end, work will be assessed according to five aspects, which are: 

contextual investigation/background research

project process and professionalism,

the deliverable,

evaluation and reflection,

exposition
Marks for any aspect will be determined by reference to a set of descriptors that relate 
various characteristics that the work exhibits to applicable mark ranges. The overall 
mark reported by an assessor will be derived from a weighted sum of the marks for the 
five aspects. To allow for legitimate variation in the nature and orientation of CS3IP 
topics, a supervisor may (within specified limits) vary the weight attached to each aspect 
and should share these changes with the second assessor.  
How the process works 
Each student will present their work to their supervisor and a second assessor (another 
staff member) in a 40-minute ‘closed demo’. The demo forms an integral part of the 
assessment process. Specifically, it enables the assessors to:
(1) assess the quality, functionality, and completeness of the deliverable (contributing to 
the Deliverable component);
(2) evaluate the student’s ability to clearly articulate, justify, and reflect on the 
development and outcomes of their work (contributing to the Exposition component).
The supervisor and second assessor read and mark the student’s report independently, 
using the five aspects, and each determine a grade. They should then share the grades 
they have arrived at, and in discussion reach a final mark. A starting point is to average 
the two grades, but if they are too disparate this may not give a meaningful result: if this 
happens consult the Module Tutor who will ask a third assessor to read the report to 
settle the dispute. In extreme cases, the Examination Board may have to become 
involved. 


================================================================================
Page 2
================================================================================
1: Project Aspects 
To comply with CS3IP requirements all projects must engage with the five aspects listed 
above, which correspond to sections of the assessment mark scheme. Depending on the 
project, the relative proportions and indeed the nature of the work done that falls under 
each aspect will vary. 
1.1: Contextual Investigation/Background Research 
Work in this area answers the question: What is the project trying to achieve, why is it 
important and what makes it different from other work in the area? 
Essentially the student needs to explain what the problem is that they want to solve (or 
question that they want to answer) with their work, what has been done in that area and 
why their solution is better. The nature of the project will determine what is involved 
here. Computing for Business students may wish to state the business case for their 
work, indeed anyone whose work is of potential commercial value should do so to some 
degree. A more research-oriented project will include a review of academic literature in 
the area under study. A project being completed for a client (real or imaginary) can 
include knowledge elicitation of the domain and from the intended user base. Both the 
rationale for and the broad objectives of the project need to be explained in this section 
of the report. 
1.2: Project Process and Professionalism 
Work in this area answers the question: How did the student plan to achieve the 
deliverable? 
This is the student’s opportunity to demonstrate their project management skills as well 
as show their understanding of the software lifecycle. For projects involving the creation 
of software, a variety of formal artefacts may be produced – for example, requirements 
specification, use case analysis, domain model, class diagram, sequence diagrams, 
storyboard, navigation structure, and test plan.  Similarly, for research-based or 
investigative projects, the process will typically involve identification of the research 
question or focus of investigation, experimental/study design, research tool design, and 
results analysis, discussion, and, where applicable, recommendations/guidelines. Critical 
decision making about tools and methodologies may be explained, including both the 
rationale for those selected and the reasons why others were discarded. 
The student’s Project Diary should be a great help in writing this section, as this 
information should be being recorded throughout the course of the project. The actual 
Diary may be added as an appendix to the report. 
1.3: Deliverable 
Work in this area answers the question: What did the project produce? 
This refers to the actual software or research outcomes that have been produced as a 
result of the project work. Whilst it should be covered in the report, the work as 
presented at the demo is of major significance here.  
For software development projects, this is the implementation of an end product, 
including testing and some documentation. There may be one or more prototype 
iterations. The aspect may include experimental application of an end product derived 
from the lifecycle activities. 


================================================================================
Page 3
================================================================================
For research-based or investigative projects, this is the analysis of results obtained from 
practical experimental sessions or from other investigative procedures. Typically, this will 
return models, recommendations, or guidelines from which clients or future researchers 
can benefit. 
1.4: Evaluation and Reflection 
Work in this area answers the question: “How do we know if the deliverable met its 
goals?” 
Whilst the Project Definition Form, submitted early in the module, provides a ‘jumping 
off point’ for what the student intends to do during the course of the project, it is 
recognised that this may change in light of initial research. Evaluation should be based 
on the specification and requirements analysis for projects that produce a piece of 
software, assessing how well the end product meets those requirements. Research-
based projects should assess how well the initial research questions or objectives have 
been answered by the work presented. 
The Reflection component of this section allows the student to assess their performance 
– e.g., time management, organisation, etc. – and reflect on how they have grown as a 
person and as a computer science professional during the course of their project. Whilst 
the report should be written in formal language, using the third person, the Reflection –
to accommodate its more personal nature – may be written in the first person.
This aspect embraces all activities and thought aimed at gaining a well justified 
summation of what the project work has achieved and what may be learned from it. 
Systematic, evidence-based comparison of project outcomes with objectives and broad 
norms of quality is fundamental. Regardless of project type, the merit of 
methods/approaches employed (e.g., any particular software processes and tools used, 
or research/investigative methods adopted) should be considered and compared with 
possible alternatives. Limitations of the project work achieved should be considered. 
Lessons learned should be outlined, along with scope for, and desirability of, further 
work/research. Where there is a client, wherever possible input should be obtained from 
the client, and an assessment made of the value that the client could derive from the 
project outcome. 
For software development projects, the usability of an end product intended for a client, 
or any other form of user should be assessed. 
For research-based or investigative projects, the significance of results obtained should 
be evaluated. 
1.5: Exposition 
Work in this area answers the question: “How well was the project work presented?” 
This covers how well the student has conveyed information about and shared 
understanding of the project to others. The primary vehicle for doing so is the report and 
the student’s ability to present their work orally via a well-organised presentation and 
demonstration as well as their competence in answering questions. 
Both the organisation and structure of the report and the clarity of the language used is 
important. Apposite illustrations – including diagrams, screenshots, and code snippets – 
should be used.  


================================================================================
Page 4
================================================================================
Particularly in the literature review and background information sections, correct citation, 
quotation, and referencing should be used, and students may be penalised if this is not 
done. The Harvard system is preferred. 
2: Grade Descriptors 
The statement against the mark of 40% is intended to indicate the minimum level the 
work should have achieved to pass that aspect of the project. 
2.1: Contextual Information/Background Research 
<40% 
Disordered fragmentary information, general knowledge level with little 
evidence of research 
40% 
The origins and purpose of the deliverable are coherently described. Any 
previous work or research that the project directly relies on is cited. Any 
client associated with the work is identified. 
41-49% 
There is evidence of an investigative element, but the outcome is presented
in a purely descriptive and/or unstructured manner with little or no 
indication of critical thought, and/or is excessively limited in scope, having 
regard to the project topic. 
50-59% 
Related practical and/or academic work is reviewed, with some evidence of
systematic and/or critical thought, with relevant references cited. Where 
applicable, the business context and processes of a client are set out in 
sufficient depth to motivate the work in general and a range of specific 
objectives. For research and investigative projects, aims and objectives are 
clearly stated. There will be a suitable description of the motivation behind 
the project. 
60-69% 
There is substantial evidence of systematic investigation and critical
thought, whether in reviewing previous work/research or in pursuing 
business analysis or in motivating subsequent work/research, as applicable. 
How the results of the contextual investigation/background research relate 
to and influence the development of the deliverable is clearly established. 
70-79% 
There is evidence of both thoroughness (e.g., in attention to detail and
scope) and depth of insight into the problems raised by the development of 
the deliverable and the range of objectives that the development pursued. 
>80%
Precursor work or research is formally cited and critically reviewed, 
probably with some original insights that augment the motivation for the 
present work/research. Business analysis (where relevant) shows a 
detailed understanding of a client’s business and the related wider business 
environment, with the project work placed in the context of critical review 
of existing processes, preferably coupled with suggestions for process 
improvement or new processes. Background research analysis shows a 
deep understanding of the research space and the related ‘bigger picture’, 
with the proposed research placed in context and its need well justified. 
2.2: Project Process and Professionalism 
<40% 
No clear plan. Work has been approached in a haphazard manner. 
Elements of the process are missing or fragmentary. 
40% 
In the case of software development projects, at least two software 
lifecycle stages towards the project objectives have been completed with 
some success; in the case of research/investigative projects, at least 
research/investigative question identification and process design have 
been completed with some success. 


================================================================================
Page 5
================================================================================
41-49%
There is work towards the design of a deliverable showing knowledge of 
recognised lifecycle activities drawn from at least two lifecycle stages or 
understanding of recognised research practice. The relationship between 
processes and artefacts and any theoretical material included in the report 
is likely to be limited and weakly evidenced. 
50-59%
Work leading to the deliverable has followed recognised stages – e.g., 
analysis, design and implementation for software development projects 
and experimental/study design and application for research projects – but 
probably with errors or omissions in application. Relevant formal artefacts 
(e.g., design documents, method descriptions) have been produced, but 
may be flawed in execution. There is evidence that processes and 
artefacts have taken account of any theoretical material included in the 
report although these may not be highlighted clearly. 
60-69%
Recognised development or research/experimental processes have been 
proficiently applied. Artefacts are in good style, showing consistent and 
effective attention to the need for quality. For research/investigative 
projects with an experimental element, experimental design is well 
reasoned and sound. There is clear evidence that processes and artefacts 
accurately reflect the recommendations drawn from the theoretical 
material included in the report. 
70-79%
The development or research/experimental process shows insight and 
innovation. There is strong evidence of consistent attention to quality. 
>80%
Work of high quality, conducted to a near-professional standard. 
2.3: The Deliverable 
<40% 
Work is fragmentary. Software does not run or shows major flaws. 
Objectives have not been attained. 
40% 
Some major objectives of the work have been achieved, resulting in a 
functional or basic research/investigative deliverable or a rational and 
credible explanation for failure to achieve a functioning system or a 
research/investigative deliverable has been given. 
41-49%
In the case of a software development project there is a deliverable with 
functionality exceeding the threshold expectation; in the case of a 
research/investigative project, there is a deliverable with 
usefulness/insight exceeding the threshold expectation. 
50-59%
There is a deliverable that broadly meets the objectives of the work, 
though there may be (for software development projects) usability flaws, 
poor reliability, or gaps in functionality or (for research/investigative 
projects) gaps in coverage, limited analysis, poor level of 
recommendation. 
60-69%
There is a deliverable that substantially meets the objectives of the work, 
with only minor flaws. For research projects, research/experimental 
design is well reasoned and sound. 
70-79%
The deliverable shows insight and innovation. There is strong evidence of 
consistent attention to quality. 
>80%
There is a deliverable characterised by, for software development 
projects, a very high standard of functionality and usability, coupled with 
originality, and for research/investigative projects, a very high standard of 
analysis. Software may be near commercial quality, research may be 
approaching a level worthy of publication. 
2.4: Evaluation and Reflection 


================================================================================
Page 6
================================================================================
<40% 
Little attempt at systematic review of the work. Analysis of personal 
performance is uncritical. Inadequate testing of any software created. 
40% 
The outcome of the work has been reviewed, with opinions expressed as 
to the successfulness of the work as a whole. Analysis of personal 
performance is basic. 
41-49%
There is some evidence of systematic evaluation, e.g., comparison of 
outcome against objectives for some requirements or against research 
hypotheses or goals in the case of research projects. Analysis of personal 
performance includes suggestions for improvement 
50-59%
There is, for software development projects, evidence of systematic 
evaluation, including comparison of outcome against objectives over a 
broad range of requirements, and attention to a wider range of issues, 
such as usability and process, as well as functionality. Client-based 
projects cite client views. For research/investigative projects, there is 
evidence of systematic evaluation such as comparison of outcomes 
against research objectives and/or research hypotheses, critical reflection 
on the research methods used, comparison of data sets, etc. Personal 
performance is analysed critically. 
60-69%
Evaluation is systematic and conducted in a manner consistent with any 
theoretical discussion included in the report. Evaluation is evidence-
based, e.g., includes user or client feedback obtained in a systematic 
manner, statistical investigation of reliability or other matters, comparison 
of research data sets, etc. There is evidence of reflection on project 
processes and outcomes, including (where applicable) the value of the 
outcome to a client. 
70-79%
Evaluation processes show evidence of careful design. There is substantial 
evidence of reflection on the processes and outcomes of the work, leading 
to exposition of insights gained from the work. 
>80%
Both evaluation of the work and personal performance has been to a high 
standard of rigour and thoroughness. Insights gained are substantial and 
show innovative thought. 
2.5: Exposition 
If the report is otherwise good but referencing is poor, inconsistent, or absent a penalty 
of up to 30% may be applied at the assessors’ discretion, with 30% being no referencing 
at all. 
<40% 
The report is muddled and incoherent, showing a poor command of 
English. Referencing is absent or poorly done. The student may have 
attended the demo, but if so, presented their work poorly and failed to 
answer questions adequately, showing little understanding of their own 
work. 
40% 
The report provides basic meaningful communication of the content and 
outcome of the work, notwithstanding the presence of major defects such 
as poor spelling and grammar or a confusing layout. The student attended 
the demo and was able to answer basic questions about their work. Some 
attempt has been made at referencing. 
41-49%
The report has an apparent structure and addresses all major areas of 
activity, though it may be unbalanced and is likely to exhibit many of the 
flaws given in the threshold descriptor. Some theoretical material may be 
included but is likely to show only limited relevance to practical work or 
research evidenced in the material provided for assessment.  
50-59%
The report presents the work/research in a logical order with reasonably 
balanced attention given to all major areas of activity. Some of the flaws 
listed in the threshold descriptor are likely to be present, though with a 


================================================================================
Page 7
================================================================================
lower frequency of errors. Presentation is clear with only occasional flaws. 
There are some useful examples and diagrams. Use is made of formal 
references and bibliography. Any theoretical material included is broadly 
relevant to practical work/research evidenced in the material provided for 
assessment. In the project demonstration/presentation, the student was 
able to explain the broad purpose of the project and some detailed 
aspects, and to answer questions on their work coherently. 
60-69%
The report includes substantial reasoned argument as well as statement 
of facts. The style of writing is appropriate to formal scientific or business 
communication. There may be occasional English or spelling errors, but 
not such as to hinder clear communication. Examples and diagrams are 
employed as a systematic aid to effective communication. Use of formal 
references, bibliography and appendices is appropriate. Theoretical 
material included is well chosen and shows a high standard of relevance 
to practical work/research evidenced in the material provided for 
assessment. In the project oral examination, the student showed a good 
grasp of the work/research at overview and detail levels and was able to 
give reasoned answers to questions. 
70-79%
The report can be described as very well written: all the expected 
material is expounded in a well organised manner, with repetition and 
irrelevance avoided. Supporting arguments show evidence of careful, 
systematic and/or innovative thought. The presentation of the report is of 
a consistently high standard. 
>80%
Writing is concise (even elegant) as well as thorough and precise. There 
are essentially no flaws in English, typography, or presentation. Examples 
and diagrams are truly illuminating. Use of formal references and 
bibliography is meticulous. 
Notes for Assessors 
Having selected a particular descriptor as giving the most accurate reflection of what has 
been achieved for a particular aspect, the assessor should choose an appropriate 
numerical mark by judging where the work falls in the range covered by the descriptor. 
A central or “standard” rating should be recorded as a mark ending in 5. Where work is 
judged to lie exactly on the boundary between adjacent descriptors, the mark given 
should be the lower end point of the range for the higher descriptor (e.g., 60%, if the 
relevant ranges are 50-59% and 60-69%). 
In accordance with School rules, an overall mark of 39% should not be given. Any case 
for a mark in the range 36-38% should be carefully reviewed to determine whether, on 
balance, there is in fact sufficient evidence of suitable work to justify a threshold pass 
mark (40%). 
The 40% threshold is intended to correspond to work approximating the threshold 
honours standard. 
For work below 40%, these general guidelines should apply: 
0-19%
Fragmentary or almost wholly ineffective activity. 
20-38%
Work/research that provides evidence of relevant knowledge and skills 
but deployed on such a limited scale or in such an ineffective manner that 
the threshold standard for the module has not been achieved. Report 
lacks any coherent structure or totally fails to address major areas of 
activity. Software missing, does not run or is unusable due to design 
flaws. 


################################################################################
[SECTION 2: VISUAL ELEMENTS - OCR EXTRACTED TEXT]
################################################################################
Total Visual Elements: 0
[No visual elements found in PDF]

================================================================================
[END OF DOCUMENT]
================================================================================
