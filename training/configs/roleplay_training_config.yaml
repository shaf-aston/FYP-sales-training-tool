# Roleplay Training Configuration
# Optimized for sales roleplay scenarios with STT/TTS integration

# Model Configuration
model:
  name: "Qwen/Qwen2.5-0.5B-Instruct"
  type: "conversation"
  cache_dir: "./model_cache"
  
# Training Parameters
training:
  num_epochs: 5
  batch_size: 4
  learning_rate: 2e-5
  warmup_steps: 100
  max_length: 512
  gradient_accumulation_steps: 2
  
  # Roleplay-specific parameters
  conversation_context_length: 3  # Number of previous turns to include
  persona_consistency_weight: 0.3
  response_quality_weight: 0.4
  sales_technique_weight: 0.3

# Data Configuration
data:
  processed_data_path: "./training/data/processed"
  conversation_file: "structured_conversations.json"
  persona_file: "extracted_personas.json"
  training_pairs_file: "training_pairs.jsonl"
  
  # Train/validation split
  train_split: 0.8
  val_split: 0.2
  
  # Data filtering
  min_conversation_length: 5
  max_conversation_length: 50
  filter_incomplete_conversations: true

# Persona Configuration
personas:
  enabled: true
  use_dynamic_personas: true
  persona_embedding_dim: 128
  
  # Persona types to focus training on
  priority_personas:
    - "Hesitant_Decision_Maker"
    - "Script_Persona_closing_phase"
    - "Script_Persona_problem_phase"
    - "Script_Persona_emotional_phase"

# STT/TTS Integration
voice:
  stt:
    enabled: true
    model: "google_cloud_stt"
    language_code: "en-US"
    sample_rate: 16000
    
  tts:
    enabled: true
    model: "google_cloud_tts"
    voice_name: "en-US-Journey-D"
    speaking_rate: 1.0
    pitch: 0.0
    
  # Voice training parameters
  voice_consistency_training: true
  emotion_detection: true
  speech_pattern_analysis: true

# Sales Training Configuration
sales_training:
  # Sales stages to train on
  stages:
    - "opening"
    - "discovery"
    - "presentation"
    - "objection_handling"
    - "closing"
  
  # Sales techniques to emphasize
  techniques:
    - "questioning"
    - "active_listening"
    - "reframing"
    - "objection_handling"
    - "closing_techniques"
    - "rapport_building"
    
  # NEPQ methodology integration
  nepq:
    enabled: true
    focus_areas:
      - "need_development"
      - "economic_buyer_identification"
      - "pain_amplification"
      - "qualification_process"

# Evaluation Configuration
evaluation:
  metrics:
    - "conversation_quality"
    - "persona_consistency"
    - "sales_effectiveness"
    - "response_relevance"
    - "objection_handling_quality"
    - "closing_success_rate"
  
  # Evaluation datasets
  test_scenarios:
    - "price_objection"
    - "time_objection"
    - "authority_objection"
    - "need_objection"
    - "trust_objection"
  
  # Quality thresholds
  quality_thresholds:
    min_conversation_score: 0.7
    min_persona_consistency: 0.8
    min_sales_effectiveness: 0.6

# Output Configuration
output:
  model_save_path: "./training/models/roleplay_chatbot"
  checkpoint_dir: "./training/checkpoints"
  logs_dir: "./training/logs"
  
  # Versioning
  save_best_model: true
  save_intermediate_checkpoints: true
  checkpoint_frequency: 500  # steps
  
  # Export formats
  export_formats:
    - "pytorch"
    - "onnx"
    - "huggingface"

# Advanced Configuration
advanced:
  # Memory optimization
  gradient_checkpointing: true
  mixed_precision: true
  dataloader_num_workers: 2
  
  # Regularization
  dropout_rate: 0.1
  weight_decay: 0.01
  
  # Early stopping
  early_stopping:
    enabled: true
    patience: 3
    min_delta: 0.001
    
  # Learning rate scheduling
  lr_scheduler:
    type: "cosine"
    T_max: 1000
    eta_min: 1e-6

# Monitoring and Logging
monitoring:
  wandb:
    enabled: true 
    project: "sales_roleplay_chatbot"
    
  tensorboard:
    enabled: true
    log_dir: "./training/logs/tensorboard"
    
  # Custom metrics tracking
  track_conversation_metrics: true
  track_persona_metrics: true
  track_sales_metrics: true
  
  # Logging frequency
  log_frequency: 50  # steps
  eval_frequency: 200  # steps
  save_frequency: 500  # steps